{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('./data/X_train_pickle.pkl')\n",
    "X_test = pd.read_pickle('./data/X_test_pickle.pkl')\n",
    "y_train = pd.read_pickle('./data/y_train_pickle.pkl')\n",
    "y_test = pd.read_pickle('./data/y_test_pickle.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "# Hyper tuning RFC within a range of degrees\n",
    "for num in range(50,151):\n",
    "    rfc = RandomForestClassifier(random_state = 23,     # like np.random.seed\n",
    "                                 n_estimators=num,      # Why do we use 100 estimators?\n",
    "                                 max_depth=8            # Why do we use a max of 8?\n",
    "                                ).fit(X_train, y_train) # run of the mill fit method with training data.\n",
    "    # predicting y hat\n",
    "    rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "    # checking accuracy\n",
    "    acc_score = accuracy_score(y_test, rfc_pred)\n",
    "    RF_accuracy = round(acc_score*100, 2)\n",
    "\n",
    "    # checking F1 Score\n",
    "    f1_sc = f1_score(y_test, rfc_pred)\n",
    "    RF_f1 = round(f1_sc*100, 2)\n",
    "    \n",
    "    # adding scores to dictionary and printing progress.     \n",
    "    scores[num] = [acc_score, f1_sc] \n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A degree of 66 results in the highest accuracy of 0.8451 but with an f1 score of 0.6268\n",
      "A degree of 51 results in the highest f1 score of 0.6281 but with an accuracy of 0.8446\n"
     ]
    }
   ],
   "source": [
    "high_acc = 0\n",
    "high_f1 = 0\n",
    "\n",
    "# Running through each result of the RandomForestClassifier scores to determine optimal degree for best f1 and/or accuracy.\n",
    "for degree, (acc_score, f1_sc) in scores.items():\n",
    "#     comparing accuracy to highest accuracy score\n",
    "    if acc_score > high_acc:\n",
    "        high_acc = acc_score\n",
    "        this_f1 = f1_sc\n",
    "        acc_deg = degree\n",
    "\n",
    "#     comparing f1 to highest f1 score\n",
    "    if f1_sc > high_f1:\n",
    "        high_f1 = f1_sc\n",
    "        this_acc = acc_score\n",
    "        f1_deg = degree\n",
    "        \n",
    "print(\"A degree of {} results in the highest accuracy of {} but with an f1 score of {}\".format(acc_deg, round(high_acc, 4), round(this_f1, 4)))\n",
    "print(\"A degree of {} results in the highest f1 score of {} but with an accuracy of {}\".format(f1_deg, round(high_f1, 4), round(this_acc, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A degree of 66 would be the best because we value accuracy the most. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
