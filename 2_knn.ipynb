{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score #classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('./data/X_train_pickle.pkl')\n",
    "X_test = pd.read_pickle('./data/X_test_pickle.pkl')\n",
    "y_train = pd.read_pickle('./data/y_train_pickle.pkl')\n",
    "y_test = pd.read_pickle('./data/y_test_pickle.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing to Hyper tune RFC using GridSearchCV\n",
    "cv = 5                             # Set how many cross validations you would like.\n",
    "neighbors = list(range(1,13))      #\n",
    "scoring = ['accuracy', 'f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only needs to be run on the first use of this notebook, or if changes have been made to the variables above.\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = [                     # GridSearchCV params requires a 'list', so we created a dictionary within the list to pass multiple params.\n",
    "    {'n_neighbors': neighbors}\n",
    "] \n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=cv,          # Just passing in the variables declared above\n",
    "                           scoring=scoring,\n",
    "                           refit='f1',\n",
    "                           n_jobs=-2,                        # the number of processors your computer will use to run this model\n",
    "                           return_train_score=True,          # \n",
    "                           verbose=50)                       # verbose > 0 gives us a progress bar to check on.\n",
    "\n",
    "# running a grid search through range of estimators and range of depth resulting in 48 fit tests.\n",
    "grid_search.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find optimal value for K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only needs to be run on the first use of this notebook, or if changes have been made \n",
    "k_range = range(1, 13)\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    score = f1_score(y_test, y_predict, average='weighted')\n",
    "    k_scores.append(score)\n",
    "    print(\"When k={}, f1 score={}\".format(k,round(score, 4)))\n",
    "%store k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r k_scores\n",
    "high_score = 0\n",
    "for index, element in enumerate(k_scores):\n",
    "    if element > high_score:\n",
    "        high_score = element\n",
    "        ind = index\n",
    "        \n",
    "print(\"The highest score is {}; when k = {}\".format(high_score, ind + 1))\n",
    "plt.plot(range(1,13),k_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The optimal k value is 11; As made evident by the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin KNN modeling using optimal K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to plot Confusion Matrix\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KNN class\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "# Use training data to fit onto knn\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the fit to predict y hat\n",
    "y_pred_class = knn.predict(X_test)\n",
    "\n",
    "# from sklearn.metrics, we use confusion_matrix and pass in the y_test and y hat; saving the result as cm.\n",
    "# this will calculate how many true positives, true negatives, false positives, and false negatives there are.\n",
    "cm = confusion_matrix(y_test,y_pred_class)\n",
    "\n",
    "# because we're aiming to predict a value over/under 50K, we set the classes appropriately. \n",
    "classes = ['<=50K', '>50K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "#         if normalized, convert the confusion matrix to a float, then divide the top quadrants by the summation of the top row\n",
    "#           and bottom quadrants by the summation of the bottom row to get a percentage for each quadrant.\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] \n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "#     Set the plt with the confusion matrix, the colors defined (in this case default)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap) # <- What is interpolation?\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes)) \n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "# what is all of this?\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, classes=classes, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of Positives that were correctly identified are 57% of the actual Positives that exist in the dataset. This is also known as Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use Recall as a way to compare the effectiveness of different algorithms because we would rather falsely predict a lower salary of an individual(False Negatives), so that they could adequately prepare themselves financially. We would not want to falsely predict higher salaries for individuals, so that they will not have to deal with financial complications(False Positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing KNN scores for comparisons.\n",
    "knn = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_class),\n",
    "    'f1': f1_score(y_test, y_pred_class)\n",
    "}\n",
    "%store knn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
