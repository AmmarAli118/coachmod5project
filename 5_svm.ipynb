{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('./data/X_train_pickle.pkl')\n",
    "X_test = pd.read_pickle('./data/X_test_pickle.pkl')\n",
    "y_train = pd.read_pickle('./data/y_train_pickle.pkl')\n",
    "y_test = pd.read_pickle('./data/y_test_pickle.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4201  326]\n",
      " [ 624  848]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.87      0.93      0.90      4527\n",
      "        >50K       0.72      0.58      0.64      1472\n",
      "\n",
      "    accuracy                           0.84      5999\n",
      "   macro avg       0.80      0.75      0.77      5999\n",
      "weighted avg       0.83      0.84      0.84      5999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "classes = ['<=50K', '>50K']\n",
    "linear_accuracy = accuracy_score(y_test,y_pred)\n",
    "linear_f1 = f1_score(y_test,y_pred)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred,target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'scores' (dict)\n"
     ]
    }
   ],
   "source": [
    "# This can be done using a GridSearch to expedite the process. \n",
    "# Because otherwise, the third cell in this section is essentially re-running the classifier using the optimal parameters that we already ran\n",
    "scores = {}\n",
    "for num in range(1,8):\n",
    "    svclassifier = SVC(kernel='poly', degree=num, gamma='scale')\n",
    "    svclassifier.fit(X_train, y_train)\n",
    "    y_pred = svclassifier.predict(X_test)\n",
    "    scores[num] = accuracy_score(y_test, y_pred)\n",
    "%store scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A degree of 1 results in the highest accuracy of 0.843\n"
     ]
    }
   ],
   "source": [
    "%store -r scores\n",
    "high = 0\n",
    "for degree, accuracy in scores.items():\n",
    "    if accuracy > high:\n",
    "        high = accuracy\n",
    "        deg = degree\n",
    "print(\"A degree of {} results in the highest accuracy of {}\".format(deg, round(high, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4208  319]\n",
      " [ 622  850]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      4527\n",
      "           1       0.73      0.58      0.64      1472\n",
      "\n",
      "    accuracy                           0.84      5999\n",
      "   macro avg       0.80      0.75      0.77      5999\n",
      "weighted avg       0.84      0.84      0.84      5999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='poly', degree=1, gamma='scale')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "poly_accuracy = accuracy_score(y_test,y_pred)\n",
    "poly_f1 = f1_score(y_test,y_pred)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='rbf', gamma='scale')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4209  318]\n",
      " [ 637  835]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      4527\n",
      "           1       0.72      0.57      0.64      1472\n",
      "\n",
      "    accuracy                           0.84      5999\n",
      "   macro avg       0.80      0.75      0.77      5999\n",
      "weighted avg       0.83      0.84      0.83      5999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "gaussian_accuracy = accuracy_score(y_test,y_pred)\n",
    "gaussian_f1 = f1_score(y_test,y_pred)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='sigmoid',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='sigmoid', gamma='scale')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4098  429]\n",
      " [ 627  845]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      4527\n",
      "           1       0.66      0.57      0.62      1472\n",
      "\n",
      "    accuracy                           0.82      5999\n",
      "   macro avg       0.77      0.74      0.75      5999\n",
      "weighted avg       0.82      0.82      0.82      5999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "sigmoid_accuracy = accuracy_score(y_test,y_pred)\n",
    "sigmoid_f1 = f1_score(y_test,y_pred)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare accuracy and f1 scores across all variation of svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy score that we compared was 0.8431405234205701 and was a result of the poly model\n",
      "The best f1 score that we compared was 0.6436955698599016 and was a result from the poly model\n"
     ]
    }
   ],
   "source": [
    "comparison_dictionary = {\n",
    "    'accuracy':{\n",
    "        'linear': linear_accuracy,\n",
    "        'poly': poly_accuracy,\n",
    "        'gaussian': gaussian_accuracy,\n",
    "        'sigmoid': sigmoid_accuracy,\n",
    "    },\n",
    "    'f1':{\n",
    "        'linear': linear_f1,\n",
    "        'poly': poly_f1,\n",
    "        'gaussian': gaussian_f1,\n",
    "        'sigmoid': sigmoid_f1,\n",
    "    }\n",
    "}\n",
    "\n",
    "# compares accuracy between models\n",
    "high_accuracy = 0\n",
    "best_model = None\n",
    "for model, accuracy in comparison_dictionary['accuracy'].items():\n",
    "    if accuracy > high_accuracy:\n",
    "        high_accuracy = accuracy\n",
    "        best_model = model\n",
    "print(\"The best accuracy score that we compared was {} and was a result of the {} model\".format(high_accuracy, best_model))    \n",
    "\n",
    "# compares f1 between models\n",
    "high_f1 = 0\n",
    "best_model = None\n",
    "for model, f1 in comparison_dictionary['f1'].items():\n",
    "    if f1 > high_f1:\n",
    "        high_f1 = f1\n",
    "        best_model = model\n",
    "print(\"The best f1 score that we compared was {} and was a result from the {} model\".format(high_f1, best_model)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in the variables below with actual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'svm' (dict)\n"
     ]
    }
   ],
   "source": [
    "SVM_f1 = poly_f1\n",
    "SVM_accuracy = poly_accuracy\n",
    "svm = {\n",
    "    'accuracy': SVM_accuracy,\n",
    "    'f1': SVM_f1\n",
    "}\n",
    "%store svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
